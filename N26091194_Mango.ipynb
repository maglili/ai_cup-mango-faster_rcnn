{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 注意\n",
    "<hr>\n",
    "本程式是在Win10環境執行，<br>\n",
    "使用jupyter notebook編寫。<br>\n",
    "\n",
    "主目錄中要有pytorch_object_detection中的資料匣，<br>\n",
    "cell會呼叫pytorch_object_detection中的程式。<br>\n",
    "\n",
    "訓練整個Train資料匣，需要花費 22 小時，<br>\n",
    "訓練時請確定vram有7G以上。<br>\n",
    "\n",
    "GPU: RTX-2070 Super<br>\n",
    "CPU: i7-10700<br>\n",
    "RAM: 16G<br>\n",
    "Python:3.8.6<br>\n",
    "torch:1.6.0<br>\n",
    "torchvision:0.7.0<br>\n",
    "\n",
    "為了在不同電腦上都順利執行，<br>\n",
    "本程式cell中的路徑都為相對路徑非絕對路徑，<br>\n",
    "重複執行同個cell將會出現錯誤。\n",
    "\n",
    "**請將下面(約程式中段)的cell取消comment，以進行訓練**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pycocotools\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若是發生路徑問題，請確認pwd在正確位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\user\\\\Documents\\\\N26091194_TENG\\\\Assignments\\\\NCKU_ML\\\\mango'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "label=[]\n",
    "image=[]\n",
    "xmin=[]\n",
    "ymin=[]\n",
    "xmax=[]\n",
    "ymax=[]\n",
    "\n",
    "with open(r'.\\C2_TrainDev\\train.csv', 'r', encoding='utf-8-sig') as fh:\n",
    "  for index,row in enumerate(fh):\n",
    "    row=row.strip()\n",
    "    row=row.split(',')\n",
    "    while True:\n",
    "      if '' in row:\n",
    "        row.remove('')\n",
    "      else:\n",
    "        break\n",
    "\n",
    "    while len(row) > 1:\n",
    "      xmin.append(float(row[1]))\n",
    "      ymin.append(float(row[2]))\n",
    "      xmax.append(float(row[3])+float(row[1]))\n",
    "      ymax.append(float(row[4])+float(row[2]))\n",
    "      label.append(row[5])\n",
    "      for idx in range(5):\n",
    "        row.remove(row[1]) \n",
    "      image.append(row[0])\n",
    "\n",
    "traindf = pd.DataFrame({'image':image, 'label':label, 'xmin':xmin, 'ymin':ymin, 'xmax':xmax, 'ymax':ymax  })\n",
    "traindf.to_pickle(r\".\\C2_TrainDev\\traindf.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"pytorch_object_detection\" folder already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "try:\n",
    "    os.mkdir(r\".\\pytorch_object_detection\")\n",
    "    print('created folder \"pytorch_object_detection\"')\n",
    "except:\n",
    "    print('\"pytorch_object_detection\" folder already exists')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\user\\Documents\\N26091194_TENG\\Assignments\\NCKU_ML\\mango\\pytorch_object_detection\n"
     ]
    }
   ],
   "source": [
    "cd .\\pytorch_object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'vision' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/pytorch/vision.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\user\\Documents\\N26091194_TENG\\Assignments\\NCKU_ML\\mango\\pytorch_object_detection\\vision\\references\\detection\n"
     ]
    }
   ],
   "source": [
    "cd .\\vision\\references\\detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import torchvision\n",
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "import transforms as T\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_one_annot(image, train_state=True):\n",
    "  if train_state:\n",
    "    boxes_array = traindf[traindf[\"image\"] == image][[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values\n",
    "  else:\n",
    "    boxes_array = validdf[validdf[\"image\"] == image][[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values\n",
    "  return boxes_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, root, transforms=None):\n",
    "    self.root = root\n",
    "    self.transforms = transforms\n",
    "    self.imgs = sorted(os.listdir(os.path.join(root, \"Train\")))\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    # load images and bounding boxes\n",
    "    img_path = os.path.join(self.root, \"Train\", self.imgs[idx])\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    box_list = parse_one_annot(self.imgs[idx], True)\n",
    "    boxes = torch.as_tensor(box_list, dtype=torch.float32)\n",
    "    num_objs = len(box_list)\n",
    "\n",
    "    # there is only one class******************************************************\n",
    "    labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "    for row in range(len(traindf[traindf['image'] == self.imgs[idx]])):\n",
    "      if traindf[traindf['image'] == self.imgs[idx]]['label'].iloc[row] == '不良-乳汁吸附':\n",
    "        labels[row] = 1\n",
    "      elif traindf[traindf['image'] == self.imgs[idx]]['label'].iloc[row] == '不良-機械傷害':\n",
    "        labels[row] = 2\n",
    "      elif traindf[traindf['image'] == self.imgs[idx]]['label'].iloc[row] == '不良-炭疽病': \n",
    "        labels[row] = 3\n",
    "      elif traindf[traindf['image'] == self.imgs[idx]]['label'].iloc[row] == '不良-著色不佳':\n",
    "        labels[row] = 4\n",
    "      else:\n",
    "        labels[row] = 5\n",
    "      \n",
    "    image_id = torch.tensor([idx])\n",
    "    area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:,0])\n",
    "\n",
    "    # suppose all instances are not crowd\n",
    "    iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "    target = {}\n",
    "    target[\"boxes\"] = boxes\n",
    "    target[\"labels\"] = labels\n",
    "    target[\"image_id\"] = image_id\n",
    "    target[\"area\"] = area\n",
    "    target[\"iscrowd\"] = iscrowd\n",
    "    if self.transforms is not None:\n",
    "      img, target = self.transforms(img, target)\n",
    "    return img, target\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### valid set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, root, transforms=None):\n",
    "    self.root = root\n",
    "    self.transforms = transforms\n",
    "    self.imgs = sorted(os.listdir(os.path.join(root, \"Dev\")))\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    # load images and bounding boxes\n",
    "    img_path = os.path.join(self.root, \"Dev\", self.imgs[idx])\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    target = {}\n",
    "    if self.transforms is not None:\n",
    "      img, target = self.transforms(img, target)\n",
    "    return img, target\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TrainDataset(root= \".\\..\\..\\..\\..\\C2_TrainDev\")\n",
    "valid_set = ValidDataset(root= r\".\\..\\..\\..\\..\\C2_TrainDev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Download and adjust the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_classes):\n",
    "  # load an object detection model pre-trained on COCO\n",
    "  model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "  # get the number of input features for the classifier\n",
    "  in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "  # replace the pre-trained head with a new on\n",
    "  model.roi_heads.box_predictor = FastRCNNPredictor(in_features,num_classes)\n",
    "   \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "  transforms = []\n",
    "  # converts the image, a PIL image, into a PyTorch Tensor\n",
    "  transforms.append(T.ToTensor())\n",
    "  if train:\n",
    "    # during training, randomly flip the training images\n",
    "    # and ground-truth for data augmentation\n",
    "    transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "  return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use our dataset and defined transformations\n",
    "train_set = TrainDataset(root= r\".\\..\\..\\..\\..\\C2_TrainDev\",transforms = get_transform(train=True))\n",
    "\n",
    "valid_set = ValidDataset(root= r\".\\..\\..\\..\\..\\C2_TrainDev\", transforms = get_transform(train=False))\n",
    "# split the dataset in train and test set\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(train_set, batch_size=1, shuffle=True, collate_fn=utils.collate_fn)\n",
    "#data_loader_test = torch.utils.data.DataLoader(valid_set, batch_size=1, shuffle=False, collate_fn=utils.collate_fn)\n",
    "#print(\"We have: {} examples,  {} are training and {} testing\".format(len(train_set)+len(valid_set) ,len(train_set), len(valid_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not avalible!\n",
      "-Training on CPU-\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('GPU:',torch.cuda.get_device_name())\n",
    "    print('-Training on GPU-')\n",
    "else:\n",
    "    print('GPU is not avalible!')\n",
    "    print('-Training on CPU-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# our dataset has six classes only \n",
    "num_classes = 6\n",
    "# get the model using our helper function\n",
    "model = get_model(num_classes)\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "# and a learning rate scheduler which decreases the learning rate by # 10x every 3 epochs\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 注意\n",
    "<hr>\n",
    "若要自行**訓練**，請將下列cell 取消comment。<br>\n",
    "請確定目前VRAM有7G以上空間。<br>\n",
    "本模型在Dev_set上需訓練22小時。<br>\n",
    "\n",
    "**請確保執行期間程式不會中斷。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torchvision\\ops\\boxes.py:101: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:766.)\n",
      "  keep = keep.nonzero().squeeze(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [ 0/10]  eta: 0:01:07  lr: 0.000560  loss: 3.1001 (3.1001)  loss_classifier: 2.7666 (2.7666)  loss_box_reg: 0.0438 (0.0438)  loss_objectness: 0.2722 (0.2722)  loss_rpn_box_reg: 0.0175 (0.0175)  time: 6.7515  data: 0.0409\n",
      "Epoch: [0]  [ 9/10]  eta: 0:00:06  lr: 0.005000  loss: 0.5879 (1.3398)  loss_classifier: 0.3951 (1.0232)  loss_box_reg: 0.0058 (0.0261)  loss_objectness: 0.1047 (0.2774)  loss_rpn_box_reg: 0.0076 (0.0131)  time: 6.7946  data: 0.0318\n",
      "Epoch: [0] Total time: 0:01:07 (6.7947 s / it)\n",
      "folder already exists\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "   # train for one epoch, printing every 10 iterations\n",
    "   train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10) \n",
    "   \n",
    "   lr_scheduler.step() # update the learning rate\n",
    "   \n",
    "\n",
    "try:\n",
    "    os.mkdir(r\".\\..\\..\\..\\..\\pytorch_object_detection\\mango\")\n",
    "except:\n",
    "    print('folder already exists')\n",
    "    pass\n",
    "torch.save(model.state_dict(), r\".\\..\\..\\..\\..\\pytorch_object_detection\\mango\\model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = get_model(num_classes = 6)\n",
    "loaded_model.load_state_dict(torch.load(r\".\\..\\..\\..\\..\\pytorch_object_detection\\mango\\model\", map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "root= r\".\\..\\..\\..\\..\\C2_TrainDev\"\n",
    "imgs = sorted(os.listdir(os.path.join(root, \"Dev\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 注意\n",
    "<hr>\n",
    "預測完整個Dev資料匣需要耗費3小時<br>\n",
    "\n",
    "**請確定執行過程不會中斷**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:05<00:00,  2.72s/it]\n"
     ]
    }
   ],
   "source": [
    "loaded_model.eval()\n",
    "files=[]\n",
    "#label_map = {'不良-乳汁吸附':1, '不良-機械傷害':2, '不良-炭疽病':3, '不良-著色不佳':4, '不良-黑斑病':5}\n",
    "class1=[]\n",
    "class2=[]\n",
    "class3=[]\n",
    "class4=[]\n",
    "class5=[]\n",
    "\n",
    "for i in tqdm(range(len(imgs)), position=0, leave=True):\n",
    "    idx = i\n",
    "    img, _ = valid_set[idx]\n",
    "                                                  \n",
    "    aa=bb=cc=dd=ee=0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = loaded_model([img])    \n",
    "                           \n",
    "    for element in range(len(prediction[0][\"scores\"])):\n",
    "        score = np.round(prediction[0][\"scores\"][element].numpy(), decimals= 4)\n",
    "        \n",
    "        if score > 0.5:\n",
    "            if prediction[0][\"labels\"][element].numpy() == 1:\n",
    "                aa=1\n",
    "            elif prediction[0][\"labels\"][element].numpy() == 2:\n",
    "                bb=1\n",
    "            elif prediction[0][\"labels\"][element].numpy() == 3:\n",
    "                cc=1\n",
    "            elif prediction[0][\"labels\"][element].numpy() == 4:               \n",
    "                dd=1\n",
    "            elif prediction[0][\"labels\"][element].numpy() == 5:\n",
    "                ee=1\n",
    "        else:\n",
    "            break\n",
    "                           \n",
    "    if aa == 1:\n",
    "        class1.append(True)\n",
    "    else:\n",
    "        class1.append(False)\n",
    "\n",
    "    if bb == 1:\n",
    "        class2.append(True)\n",
    "    else:\n",
    "        class2.append(False)\n",
    "\n",
    "    if cc == 1:\n",
    "        class3.append(True)\n",
    "    else:\n",
    "        class3.append(False)\n",
    "\n",
    "    if dd == 1:\n",
    "        class4.append(True)\n",
    "    else:\n",
    "        class4.append(False)\n",
    "\n",
    "    if ee == 1:\n",
    "        class5.append(True)\n",
    "    else:\n",
    "        class5.append(False)\n",
    "    \n",
    "    files.append(imgs[i])\n",
    "                           \n",
    "\n",
    "pred_df = pd.DataFrame({'image_id':files,'d0':class1,'d1':class2, 'd2':class3,  'd3':class4, 'd4':class5 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已輸出結果至C2_TrainDev資料匣，請前往察看\n"
     ]
    }
   ],
   "source": [
    "pred_df.to_pickle(r\".\\..\\..\\..\\..\\C2_TrainDev\\N26091194_predict.pkl\")\n",
    "pred_df.to_csv(r\".\\..\\..\\..\\..\\C2_TrainDev\\N26091194_predict.tsv\", sep = '\\t')\n",
    "print('已輸出結果至C2_TrainDev資料匣，請前往察看')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
